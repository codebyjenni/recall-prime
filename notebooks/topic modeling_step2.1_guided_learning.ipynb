{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Guided Learning Approach\n",
    "We have implement a series of clustering models and get some meaningful topics for now. This script helps us to allocate the renamed and re-summmarised proper topics back to each answer.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get embeddings of renamed topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in the renamed topics\n",
    "import pandas as pd\n",
    "topics=pd.read_csv(\"06 Data analysis/04 Topic Modeling/outputs/GPT_summarization/ds1_sub_clustering_sum/m_hdb_dm100_sz60_sub_topics_info_Human_Refined.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "from openai import OpenAI\n",
    "from tenacity import retry, stop_after_attempt, wait_random_exponential\n",
    "import numpy as np\n",
    "\n",
    "def log_before_retry(retry_state):\n",
    "    \"\"\"Log detailed information before each retry.\"\"\"\n",
    "    exception_message = retry_state.outcome.exception() if retry_state.outcome and retry_state.outcome.exception() else 'No exception'\n",
    "    print(f\"Preparing for Retry {retry_state.attempt_number} due to {exception_message}\")\n",
    "\n",
    "\n",
    "class OpenAI_Embeddinger:\n",
    "    def __init__(self,text_ds:pd.DataFrame):\n",
    "        self.client =OpenAI() # Initialize client and model\n",
    "        self.text_ds=text_ds.reset_index(drop=True)\n",
    "        self.embedding_dict=dict()\n",
    "       \n",
    "    @retry(wait=wait_random_exponential(min=1, max=60),\n",
    "           stop=stop_after_attempt(6),\n",
    "           before_sleep=log_before_retry)\n",
    "    def get_embedding_batch(self, texts,embedding_model):\n",
    "        responses =  self.client.embeddings.create(input=texts, model=embedding_model)\n",
    "        embeddings = [None] * len(texts)  # Initialize a list to store embeddings in order\n",
    "        for response in responses.data:\n",
    "                embeddings[response.index] = response.embedding  # Store the embedding using the index to maintain order\n",
    "        return embeddings\n",
    "\n",
    "    def append_embedding(self, answer_id_column_name:str,text_column_name: str, model:str,batch_size:int):\n",
    "        print(batch_size)\n",
    "        # Generate batches from the dataset\n",
    "        self.text_ds=self.text_ds.dropna(subset=[text_column_name]).reset_index(drop=True)\n",
    "        texts = self.text_ds[text_column_name].to_list()\n",
    "        batches = [texts[i:i + batch_size] for i in range(0, len(texts), batch_size)]\n",
    "        total_batch_num = len(batches)\n",
    "        print(\"calling api started!\")\n",
    "        # Loop through each batch to process and store embeddings\n",
    "        for batch_number, batch in enumerate(batches, start=1):\n",
    "            start_index = (batch_number - 1) * batch_size\n",
    "            end_index = start_index + len(batch)-1\n",
    "            answer_names=self.text_ds.loc[start_index:end_index,answer_id_column_name]\n",
    "            embeddings = self.get_embedding_batch(texts=batch, embedding_model=model)\n",
    "            # we need to store the embeddings back into the dataset\n",
    "            batch_dict= {name: array for name, array in zip(answer_names, embeddings)}\n",
    "            self.embedding_dict.update(batch_dict)\n",
    "            print(f\"Batch {batch_number}/{total_batch_num} done!\")\n",
    "\n",
    "        # Indicate the end of the function with a suitable return or simply end the function\n",
    "        print(\"All batches processed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#call a SOTA embedding model: OpenAI's text-embedding-3-large to retrieve the vector representation of the topics \n",
    "\n",
    "# call_embedding_renamed_no_power=OpenAI_Embeddinger(text_ds=topics)\n",
    "# call_embedding_renamed_no_power.append_embedding(\"topic_id\",\"renamed_no_power\",\"text-embedding-3-large\",batch_size=20)\n",
    "# embedding_no_power=call_embedding_renamed_no_power.embedding_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# call_embedding_renamed_full_power=OpenAI_Embeddinger(text_ds=topics)\n",
    "# call_embedding_renamed_full_power.append_embedding(\"topic_id\",\"renamed_full_power_information\",\"text-embedding-3-large\",batch_size=20)\n",
    "# embedding_full_power=call_embedding_renamed_full_power.embedding_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# call_embedding_renamed_full_power2_refined=OpenAI_Embeddinger(text_ds=topics)\n",
    "# call_embedding_renamed_full_power2_refined.append_embedding(\"topic_id\",\"renamed_full_power_information2_refined\",\"text-embedding-3-large\",batch_size=20)\n",
    "# embedding_full_power2_refined=call_embedding_renamed_full_power2_refined.embedding_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# call_embedding_renamed_no_power2=OpenAI_Embeddinger(text_ds=topics)\n",
    "# call_embedding_renamed_no_power2.append_embedding(\"topic_id\",\"renamed_no_power2_refined\",\"text-embedding-3-large\",batch_size=20)\n",
    "# embedding_no_power2_refined=call_embedding_renamed_no_power2.embedding_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# call_embedding_renamed_no_power3=OpenAI_Embeddinger(text_ds=topics)\n",
    "# call_embedding_renamed_no_power3.append_embedding(\"topic_id\",\"renamed_no_power3_splitted\",\"text-embedding-3-large\",batch_size=20)\n",
    "# embedding_no_power3_splitted=call_embedding_renamed_no_power3.embedding_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #save them \n",
    "import pickle\n",
    "def pickle_write_file(object, path):\n",
    "    with open(path, 'wb') as file:\n",
    "        pickle.dump(object, file, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "# pickle_write_file(embedding_GPT,\"06 Data analysis/04 Topic Modeling/outputs/embeddings/ds1_GPT_Human_summary_embedding/topic_embedding_GPT_sum_dict\" )\n",
    "# pickle_write_file(embedding_human,\"06 Data analysis/04 Topic Modeling/outputs/embeddings/ds1_GPT_Human_summary_embedding/topic_embedding_human_renamed_dict\")\n",
    "# pickle_write_file(embedding_no_power, \"06 Data analysis/04 Topic Modeling/outputs/embeddings/ds1_GPT_Human_summary_embedding/topic_embedding_no_power_dict\")\n",
    "# pickle_write_file(embedding_no_power2_refined, \"06 Data analysis/04 Topic Modeling/outputs/embeddings/ds1_GPT_Human_summary_embedding/topic_embedding_no_power2_refined_dict\")\n",
    "# pickle_write_file(embedding_no_power3_splitted, \"06 Data analysis/04 Topic Modeling/outputs/embeddings/ds1_GPT_Human_summary_embedding/topic_embedding_no_power3_splitted_dict\")\n",
    "# pickle_write_file(embedding_full_power, \"06 Data analysis/04 Topic Modeling/outputs/embeddings/ds1_GPT_Human_summary_embedding/topic_embedding_full_power_dict\")\n",
    "# pickle_write_file(embedding_full_power2_refined, \"06 Data analysis/04 Topic Modeling/outputs/embeddings/ds1_GPT_Human_summary_embedding/topic_embedding_full_power2_refined_dict\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the embedding of topic column Human_renamed1 and topic column GPT_summ_raw have been previously retrieved,\n",
    "# we do not call them again, we just let load them \n",
    "\n",
    "#define functions of writing and loading with pickle \n",
    "import pickle\n",
    "def pickle_load_file(path):\n",
    "    with open(path, 'rb') as file:\n",
    "        object=pickle.load(file)\n",
    "    return object \n",
    "\n",
    "\n",
    "#load the previously reterieved embeddings \n",
    "embedding_GPT=pickle_load_file(\"06 Data analysis/04 Topic Modeling/outputs/embeddings/ds1_GPT_Human_summary_embedding/topic_embedding_GPT_sum_dict\" )\n",
    "embedding_human=pickle_load_file(\"06 Data analysis/04 Topic Modeling/outputs/embeddings/ds1_GPT_Human_summary_embedding/topic_embedding_human_renamed_dict\")\n",
    "\n",
    "embedding_no_power=pickle_load_file(\"06 Data analysis/04 Topic Modeling/outputs/embeddings/ds1_GPT_Human_summary_embedding/topic_embedding_no_power_dict\")\n",
    "embedding_no_power2_refined=pickle_load_file(\"06 Data analysis/04 Topic Modeling/outputs/embeddings/ds1_GPT_Human_summary_embedding/topic_embedding_no_power2_refined_dict\")\n",
    "embedding_no_power3_splitted=pickle_load_file(\"06 Data analysis/04 Topic Modeling/outputs/embeddings/ds1_GPT_Human_summary_embedding/topic_embedding_no_power3_splitted_dict\")\n",
    "\n",
    "\n",
    "\n",
    "embedding_full_power=pickle_load_file(\"06 Data analysis/04 Topic Modeling/outputs/embeddings/ds1_GPT_Human_summary_embedding/topic_embedding_full_power_dict\" )\n",
    "embedding_full_power2_refined=pickle_load_file( \"06 Data analysis/04 Topic Modeling/outputs/embeddings/ds1_GPT_Human_summary_embedding/topic_embedding_full_power2_refined_dict\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "#join the embedding dictionaries back to the dataset so our potential readers and reviwers can check our outputs more conveniently\n",
    "topics[\"embedding_GPT\"]=topics[\"topic_id\"].map(embedding_GPT)\n",
    "topics[\"embedding_human\"]=topics[\"topic_id\"].map(embedding_human)\n",
    "topics[\"embedding_no_power\"]=topics[\"topic_id\"].map(embedding_no_power)\n",
    "topics[\"embedding_no_power2_refined\"]=topics[\"topic_id\"].map(embedding_no_power2_refined)\n",
    "topics[\"embedding_no_power3_splitted\"]=topics[\"topic_id\"].map(embedding_no_power3_splitted)\n",
    "topics[\"embedding_full_power\"]=topics[\"topic_id\"].map(embedding_full_power)\n",
    "topics[\"embedding_full_power2_refined\"]=topics[\"topic_id\"].map(embedding_full_power2_refined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "#change embedding in numpy array to list so that they will be fully saved in a csv table \n",
    "\n",
    "topics[\"embedding_GPT\"]=[ list(x) if not np.isnan(x).any() else float('nan')  for x in topics[\"embedding_GPT\"]]\n",
    "topics[\"embedding_human\"]=[ list(x) if not np.isnan(x).any() else float('nan') for x in topics[\"embedding_human\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#also save the table \n",
    "topics.to_csv( \"06 Data analysis/04 Topic Modeling/outputs/embeddings/ds1_GPT_Human_summary_embedding/ds1_topics_embedding_with_topic_text.csv\",index=False )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pairwise relevance between each topic and each response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in dataset1 and the embeddings of each answer\n",
    "text_df=pd.read_csv(\"data/dataset1_text_ID_created.csv\")\n",
    "#join the embedding back to the dataset\n",
    "text_df[\"embedding\"]=text_df[\"text_id\"].map(pickle_load_file(\"06 Data analysis/04 Topic Modeling/outputs/embeddings/ds1_text_embedding\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define a function to get pairwise embedding\n",
    "import re \n",
    "def get_pairwise_embedding(targeted_topic_embedding_column:str):\n",
    "    topics_df=topics[[\"topic_id\",targeted_topic_embedding_column]].dropna()\n",
    "    pw_df=pd.DataFrame(cosine_similarity( np.stack(text_df[\"embedding\"]),np.stack(topics_df[targeted_topic_embedding_column])),\n",
    "             index=text_df[\"text_id\"],\n",
    "             columns=topics_df[\"topic_id\"] ) \n",
    "    pw_df.to_csv(f\"06 Data analysis/04 Topic Modeling/outputs/ds1_ex_post_guided_learning/pairwise_relevance/pw_relevance_topics{re.sub('embedding','',targeted_topic_embedding_column)}.csv\")\n",
    "\n",
    "    return pw_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "pw_relevance_GPT=get_pairwise_embedding(\"embedding_GPT\" )\n",
    "pw_relevance_human1=get_pairwise_embedding(\"embedding_human\" )\n",
    "pw_relevance_no_power=get_pairwise_embedding(\"embedding_no_power\" )\n",
    "pw_relevance_no_power2=get_pairwise_embedding(\"embedding_no_power2_refined\" )\n",
    "pw_relevance_no_power3=get_pairwise_embedding(\"embedding_no_power3_splitted\" )\n",
    "pw_relevance_full_power=get_pairwise_embedding(\"embedding_full_power\" )\n",
    "pw_relevance_full_power2=get_pairwise_embedding( \"embedding_full_power2_refined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_write_file(pw_relevance_no_power3, \"06 Data analysis/04 Topic Modeling/outputs/ds1_ex_post_guided_learning/pairwise_relevance/pw_relevance_topics_no_power3_splitted.DataFrame\" )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "text_experiment_p",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
