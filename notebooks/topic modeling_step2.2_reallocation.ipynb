{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Re-allocation\n",
    "This is the final step of topic modeling. \n",
    "\n",
    "In the first step, we used a SOTA embedding model to retrieve the vector representations of all answers and implement a bunch of clustering models. By checking the intrinsic metrics, extrinsic metrics, and the clusters in 2D plots, we believe the HDBSCAN model with 100 dim of features and 60 min_sample/min_cluster size generate the best result. We then call the SOTA generative model to summarise the topic of each cluster. Then in the second step, we want to further combine, add, split, or fine-tune the topics to make them even more reasonable from the human perspective. We tried a series of re-summarisations and repeatedly review the results of re-allocation based on these different topics.  We finally decided on one set of topics. \n",
    "\n",
    "Now in the third step, we are going to do a final re-allocation of the points, keeping the original clustering information as much as possible while adapting to the re-summarised set of topics. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in the original clustering results, re-summarised set of topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the original clustering \n",
    "import pandas as pd\n",
    "m_hdb10060_results=pd.read_csv(\"06 Data analysis/04 Topic Modeling/outputs/GPT_summarization/ds1_sub_clustering_sum/m_hdb_dm100_sz60_sub_all_rows.csv\",\n",
    "                               usecols=[\"text_id\",\"cluster_topic\"]).rename(columns = {'cluster_topic':'hdb10060_original'})\n",
    "m_hdb10040_results=pd.read_csv(\"06 Data analysis/04 Topic Modeling/outputs/GPT_summarization/ds1_sub_clustering_sum/m_hdb_dm100_sz40_sub_all_rows.csv\",\n",
    "                               usecols=[\"text_id\",\"cluster_topic\"]).rename(columns = {'cluster_topic':'hdb10040_original'})\n",
    "academic_text_id_list_hdb10040=list(m_hdb10040_results.query( \"hdb10040_original=='Power Imbalance in Academic Grading'\")[\"text_id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all answers\n",
    "text_df=pd.read_csv(\"06 Data analysis/00 data/python_datasets/dataset1_text_ID_created.csv\")\n",
    "\n",
    "#join the clustering of original HDB model to each answer\n",
    "text_df=pd.merge(left=text_df,right=m_hdb10060_results,on=\"text_id\",how=\"left\")\n",
    "text_df.loc[text_df[\"hdb10060_original\"].isna(), \"hdb10060_original\"] = \"Relevant_PNAS_0\"\n",
    "text_df.loc[text_df[\"hdb10060_original\"] == \"Experiences of Powerlessness and Regaining Control\", \"hdb10060_original\"] = \"Other\"\n",
    "\n",
    "import re \n",
    "text_df[\"hdb10060_original\"]=[re.sub(r'\"','',text)  for text in text_df[\"hdb10060_original\"]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in re-summarised set of topics\n",
    "topics=pd.read_csv(\"06 Data analysis/04 Topic Modeling/outputs/GPT_summarization/ds1_sub_clustering_sum/m_hdb_dm100_sz60_sub_topics_info_Human_Refined.csv\",\n",
    "                   usecols=[\"topic_id\",\"GPT_summ_raw\", \"renamed_no_power3_splitted\"]).rename(columns = {'renamed_no_power3_splitted':'re_summarised_topic'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in the pre-calculated pairwise similarities between each answer and each topic \n",
    "import pickle\n",
    "with open(\"06 Data analysis/04 Topic Modeling/outputs/ds1_ex_post_guided_learning/pairwise_relevance/pw_relevance_topics_no_power3_splitted.DataFrame\" , 'rb') as file:\n",
    "    pw_sim=pickle.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Re-allocate each answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#joined the renamed topics (points are not re-allocated at this point), a temporary column\n",
    "\n",
    "# text_df.drop(columns=[\"renamed_topics\",\"renamed_topics\"],inplace=True)\n",
    "text_df=pd.merge(left=text_df,right=topics.drop(index=[0,2,4,10]),\n",
    "                 left_on=\"hdb10060_original\",right_on=\"GPT_summ_raw\",\n",
    "                how=\"left\").drop(columns=[\"topic_id\",\"GPT_summ_raw\"]).rename(columns={ \"re_summarised_topic\":\"renamed_topics\"} )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics.set_index( \"topic_id\",drop=False,inplace=True)\n",
    "\n",
    "# the logic of re-allocating each row \n",
    "def re_allocate_each_answer( row):\n",
    "# if clustered as academic grading in the HDB_100_40 model, directly keep the results \n",
    "    if row[\"text_id\"] in academic_text_id_list_hdb10040:\n",
    "        return topics.loc[\"Topic_13_Acade...\"][\"re_summarised_topic\"]\n",
    "# if clustered as noise or not included in clustering, we directly allocate it to the nearest topic\n",
    "    if row[\"hdb10060_original\"] in [\"Other\", \"Relevant_PNAS_0\",\"Experiences of Power Dynamics in Influence and Control Over Desired Outcomes\"]:\n",
    "        return topics.loc[pw_sim.loc[row[\"text_id\"]].idxmax()][\"re_summarised_topic\"]\n",
    "# if closest to academic grading or nonsense, directly allocate it to these two topics we added \n",
    "    if pw_sim.loc[row[\"text_id\"]].idxmax() in [\"Topic_13_Acade...\",\"Topic_14_Nonse...\"]:\n",
    "        return topics.loc[pw_sim.loc[row[\"text_id\"]].idxmax()][\"re_summarised_topic\"]\n",
    "# merge the two topics related to job, workplace or professional context \n",
    "    if row[\"hdb10060_original\"] in [\"Professional Leadership and Decision-Making Experiences\",\n",
    "                                    \"Feelings of powerlessness and lack of control in the workplace due to managerial decisions and authority.\"]:\n",
    "        return topics.loc[\"Topic_1_Profe...\"][\"re_summarised_topic\"]\n",
    "# put the answer related to relationships into the most proper one \n",
    "    if row[\"hdb10060_original\"] ==\"Exerting Control Over Dependents (Children, Siblings, or Pets)\":\n",
    "        return topics.loc[pw_sim[[\"Topic_5_Relat...\",\"Topic_11_Relat...\",\"Topic_15_Sibli…\", \"Topic_16_Pets…\",\"Topic_17_Friends…\"]].loc[row[\"text_id\"]].idxmax()][\"re_summarised_topic\"]\n",
    "    if row[\"hdb10060_original\"] ==\"Experiencing Feelings of Powerlessness and Control in Relationships\":\n",
    "        return topics.loc[pw_sim[[\"Topic_11_Relat...\", \"Topic_17_Friends…\"]].loc[row[\"text_id\"]].idxmax()][\"re_summarised_topic\"]\n",
    "# for the rest of points, keep the orginal clustering information and just return the modified names \n",
    "    return row[\"renamed_topics\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_df[\"re_allocation\"]=text_df.apply(re_allocate_each_answer,axis=1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we also create a column without any re-allocation of \n",
    "text_df[\"re_allocation_without_RelePANS0\"]=text_df[\"re_allocation\"]\n",
    "text_df.loc[text_df[\"Relevant_PNAS\"]==0, \"re_allocation_without_RelePANS0\"] = \"Relevant_PNAS_0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_df.drop(columns=[\"renamed_topics\"]).to_csv( \"06 Data analysis/04 Topic Modeling/outputs/final_topic_modeling_results/ds1_topic_modeling_results.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plots of topics X power conditions\n",
    "\n",
    "We use Plotly to create our plots of topic per condition instead of Bertopic since we have customized clustering results. \n",
    "\n",
    "\n",
    "The default normalization in topics_per_class in bertopic uses l2 normalization to first normalize the frequencies of conditions in each topic and then plot the topics per condition using normalized values. In this way, the values per condition eliminate the differences in the size of different topics. \n",
    "\n",
    "\n",
    "We will use the same way in our customized codes. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_df=pd.read_csv(\"06 Data analysis/04 Topic Modeling/outputs/final_topic_modeling_results/ds1_topic_modeling_results.csv\" )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Condition\n",
       "LP                 3460\n",
       "HP                 2442\n",
       "C (Grocery)        1440\n",
       "C (Last Meal)       624\n",
       "C (Equal Power)     434\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_df[\"Condition\"].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "abbreviations = {\n",
    "    'HP': 'High Power',\n",
    "    'LP': 'Low Power',\n",
    "    'C (Grocery)': 'Grocery',\n",
    "    'C (Last Meal)': 'Last Meal',\n",
    "    'C (Equal Power)':'Equal Power'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_df['Condition'] = text_df['Condition'].replace(abbreviations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "\n",
    "\n",
    "# Group by class and topic to get the counts\n",
    "\n",
    "def plot_normalized_topic_per_condition( clustering_result_df,condition_column_name='Condition',topic_column_name='re_allocation'):\n",
    "    # first group a clustering result into the counts of each condition and each topic\n",
    "    topics_per_class = clustering_result_df.groupby([condition_column_name,topic_column_name ]).size().reset_index(name='counts')\n",
    "    # Define function to normalize the distributions on conditions by each topic \n",
    "    def normalize_group(group):\n",
    "        group['normalized_frequency'] = normalize(group[['counts']], axis=0)\n",
    "        return group\n",
    "    topics_per_class = topics_per_class.groupby(topic_column_name).apply(normalize_group).reset_index(drop=True)\n",
    "    \n",
    "    #create plots\n",
    "    fig = px.bar(topics_per_class, y=condition_column_name, x='normalized_frequency', color=topic_column_name, barmode='group', orientation='h',\n",
    "             title='Topics per Condition', color_discrete_sequence= px.colors.qualitative.Light24)\n",
    "\n",
    "    # Customize the layout\n",
    "    fig.update_layout(\n",
    "    width=1500,\n",
    "    height=2000,\n",
    "    yaxis_title='Condition',\n",
    "    xaxis_title='Normalized Frequency',\n",
    "    legend_title='Topic',\n",
    "    template='plotly_white'\n",
    "    )\n",
    "\n",
    "\n",
    "    return fig\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all points \n",
    "plot_normalized_topic_per_condition( text_df).write_html( \"06 Data analysis/04 Topic Modeling/outputs/visual_topicXcondition/ds1_topicXcondition_final.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# excluding PANS0 points \n",
    "plot_normalized_topic_per_condition( text_df[text_df[\"Relevant_PNAS\" ]==1]).write_html( \"06 Data analysis/04 Topic Modeling/outputs/visual_topicXcondition/ds1_topicXcondition_final_no_PNAS0.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
